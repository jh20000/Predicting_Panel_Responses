# 설문 응답 예측 모델 개발  
**분류 문제 | 평가 기준: Accuracy | 최종 분반 기준 성능 2위 달성**

---

## 1. 프로젝트 개요

- **목표**: 패널 정보 및 설문 데이터를 기반으로 응답 여부(`STATUS`)를 예측하는 머신러닝 모델 개발
- **데이터 구성**:
  - `train.csv`: 813,650건
  - `test.csv`: 541,867건
  - 총 44개 컬럼 (패널 속성, 설문 정보, 응답 여부 포함)

---

## 2. 데이터 전처리 및 Feature Engineering

### 🔹 결측치 및 입력값 정리

- **결측치 처리**  
  - 범주형 feature → 최빈값  
  - 수치형 feature → 평균값  

- **컬럼 제거**  
  - 결측률 30% 이상  
  - 공백/오입력 등으로 인해 동일한 값이 다르게 분류된 경우 정리  
    - 예: `'남'`, `' 남자'`, `'남자 '` → `'남자'`로 통일

---

### 🔹 주요 Feature Engineering

- **응답률 기반 변수**
  - 패널별 응답률
  - 설문별 응답률
  - 패널 타입별 응답률  
  → 소수점 6자리까지의 미세 차이로 인한 과적합 방지를 위해 **소수점 3자리에서 round 처리 후 구간화**

- **설문 제목 포함 여부**
  - `title`에 `'해외'`, `'소비자'`, `'일반인'` 키워드 포함 여부에 따라 이진 변수 생성

- **리워드/시간 관련 변수**
  - 리워드 점수, 설문 소요시간, 난이도 등을 조합한 파생 변수 생성  
  - 리워드가 높고 시간이 짧은 설문일수록 응답 확률이 높다고 가정

- **패널 성향 관련 변수**
  - 총 응답 횟수 (로그 변환)
  - 평균 리워드 점수
  - 누적 획득 포인트 (구간화)

---

### 🔹 Feature Transformation

- 수치형 feature → `StandardScaler`  
- 범주형 feature → `Ordinal Encoding`

---

## 3. 모델링 및 성능 개선

### 🔹 모델 실험

- **Baseline 모델**: DecisionTree, RandomForest, Ridge, Lasso, Bagging 등  
- **최종 모델**: LightGBM, CatBoost, XGBoost  
  → Optuna 튜닝 또는 EarlyStopping 적용하여 성능 최적화

---

### 🔹 Feature Selection (SHAP 기반)

- SHAP 라이브러리를 활용해 feature importance 시각화 및 해석
- 중요도가 낮은 feature 일부 제거 (32개 → 29개)
- 그러나 **원본 feature 전체를 사용할 때 Private Score가 더 우수**
  - SHAP은 훈련 데이터 기반의 상대적 중요도를 계산하기 때문에,  
    **상호작용 feature나 예외 처리를 담당하는 변수는 저평가될 수 있음**
  - → 단일 기준에 의존한 feature 제거의 위험성 경험
  - 
<img width="790" height="940" alt="image" src="https://github.com/user-attachments/assets/77ad4ed2-e449-403f-8efb-d451c88d546d" />

---

### 🔹 앙상블 구조 및 최종 예측

- **5-Fold OOF 교차검증** 기반 모델 학습
- fold별 예측값을 Soft Voting하여 최종 예측
  - Threshold를 0.48~0.52로 실험 → `0.495`가 가장 안정적이어서 최종 적용

- 이후 입력 데이터(X)에 대해
  - `log`, `sqrt`, `MinMax Scaling`을 각각 적용
  - 동일한 5-Fold 방식으로 재학습
- 세 방식의 결과를 Hard Voting하여 최종 예측값 생성  
  → 서로 다른 데이터 분포를 가정한 모델들을 결합하여 **안정성과 일반화 성능 향상**

---

## 4. 결과 요약 및 회고

- **응답률 기반 feature**가 성능에 가장 큰 영향을 주었으며,  
  단순 모델링 기법보다 **데이터 해석 및 feature 설계의 정교함이 성능 향상의 핵심**이었음

- 과도한 소수점 정밀도로 인해 응답률 feature가 과적합되는 경향을 보여  
  → **소수점 3자리에서 round 처리**하고 구간화하여 일반화 성능 향상

- SHAP 기반 feature selection 과정에서는,  
  성능이 오히려 하락하는 경우를 경험  
  → 단일 기준에 따른 feature 제거보다 **데이터 기반 해석과 직관이 병행되어야 함**

- 최종 모델은 복잡한 구조를 가졌지만,  
  데이터량이 충분하고 클래스 불균형이 크지 않아 해당 구조가 유효하게 작동함

- **이번 프로젝트는 단순한 성능 향상을 넘어서,  
  데이터 탐색 → feature 설계 → 앙상블 전략 → 모델 선택까지의 전체 흐름을 처음부터 끝까지 경험한 기회였음**

---

## 5. 파일 안내

- `MLcompetition.ipynb`: 전체 실험 및 결과 포함
- `README.md`: 실험 과정과 전략 설명 (본 문서)

