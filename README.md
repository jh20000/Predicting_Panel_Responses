# 설문 응답 예측 모델 개발  
분류 문제 | 평가 기준: Accuracy | 최종 분반 기준 성능 2위 달성

---

## 1. 프로젝트 개요

- 목표: 패널 정보 및 설문 데이터를 기반으로 응답 여부(`STATUS`)를 예측하는 머신러닝 모델 개발
- 데이터 구성:
  - `train.csv`: 813,650건
  - `test.csv`: 541,867건
  - 총 44개 컬럼 (패널 속성, 설문 정보, 응답 여부 포함)

---

## 2. 데이터 전처리 및 변수 설계 (Feature Engineering)

### 🔹 결측치 및 입력값 정리

- 결측치 처리  
  - 범주형 변수: 최빈값 대체  
  - 수치형 변수: 평균값 대체

- 컬럼 제거  
  - 결측률 30% 이상  
  - 공백/오입력으로 인해 동일한 값이 다르게 표기된 항목 정제  
    - 예: `'남'`, `' 남자'`, `'남자 '` → `'남자'`로 통일

---

### 🔹 주요 파생 변수 설계

- 응답률 기반 변수  
  - 패널별 응답률  
  - 설문별 응답률  
  - 패널 타입별 응답률  
  → 소수점 6자리까지의 과도한 정밀도는 과적합 유발 → 소수점 3자리에서 반올림 후 구간화

- 설문 제목 포함 키워드  
  - `title`에 `'해외'`, `'소비자'`, `'일반인'` 키워드 포함 여부에 따라 이진 변수 생성

- 리워드/시간 관련 변수  
  - 리워드 점수, 설문 소요시간, 난이도 등을 조합하여 응답 확률에 영향을 줄 수 있는 변수 구성  
  - 예: `CPI / LOI`, `-(LOI + IR)` 등

- 패널 성향 관련 변수  
  - 총 응답 횟수 (로그 변환)  
  - 평균 리워드 점수  
  - 누적 획득 포인트 (구간화)

---

### 🔹 변수 변환 및 스케일링

- 수치형 변수: StandardScaler  
- 범주형 변수: Ordinal Encoding

---

## 3. 모델링 및 성능 개선 전략

### 🔹 모델 실험

- 초기 실험 모델: DecisionTree, RandomForest, Ridge 등  
- 최종 선정 모델: LightGBM, CatBoost, XGBoost  
  → Optuna 튜닝 또는 EarlyStopping 적용하여 성능 개선

---

### 🔹 변수 선택 (SHAP 기반)

- SHAP을 활용하여 변수 중요도를 시각화하고 해석  
- 중요도가 낮은 일부 변수 제거 (32개 → 29개)  
- 그러나 최종 성능은 전체 변수를 사용했을 때 더 우수함  
  → 단일 기준(SHAP 값)에 의한 변수 제거는 위험할 수 있음  
  → 변수 간 상호작용, 예외 케이스 대응 등은 단순 중요도 지표로는 반영되지 않음  

---

### 🔹 앙상블 구조 및 최종 예측

- 5-Fold OOF(Out-Of-Fold) 교차검증으로 학습  
- fold별 예측 확률을 평균내어 Soft Voting 수행  
  - Threshold 0.48~0.52 실험 → 0.495에서 가장 안정적인 성능 확인  
- 이후 입력 데이터에 log, sqrt, MinMax scaling 각각 적용 후 같은 방식으로 모델 학습  
- 세 방식의 결과를 Hard Voting으로 통합 → **다양한 데이터 분포에 대한 적응력 확보**

---

## 4. 결과 요약 및 회고

- 응답률 기반 변수들이 모델 성능에 가장 크게 기여함  
- 정교한 파생 변수 설계가 단순 모델링 기법보다 더 큰 영향력을 가짐  
- SHAP 기반 변수 제거는 실제 성능 저하로 이어짐 → **직관과 데이터 해석이 함께 병행되어야 함**  
- 복잡한 구조의 모델이라도, 데이터 규모와 불균형이 문제되지 않는 상황에선 유효하게 작동함  
- 단순한 성능 향상을 넘어서, **데이터 탐색 → 변수 설계 → 모델 선정 → 앙상블 전략까지 전 과정을 경험한 프로젝트**

---

## 5. 참고 파일 안내

- `MLcompetition.ipynb`: 전체 실험 및 결과 코드 포함
- `README.md`: 실험 개요 및 전략 설명 (본 문서)
